{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, building a Pandas dataframe and saving it as a  .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73196eb43b9741fc988eedb97fe7a48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import string\n",
    "from pprint import pprint\n",
    "from collections import Counter, OrderedDict\n",
    "import math\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_PATH = '/home/parth/BE_Project/my_EmailRecommmendation'\n",
    "\n",
    "folder_path = \"/home/parth/BE_Project/my_EmailRecommmendation/Scraping/mini_deb/*\"\n",
    "file_name = BASE_PATH + \"/model/dataframe3.csv\"\n",
    "file_name1 = BASE_PATH + \"/model/dataframe4.csv\"\n",
    "file_name2 = BASE_PATH + \"/model/dataframe5.csv\"\n",
    "sys.path.insert(0, BASE_PATH + '/Preprocessing')\n",
    "PATH = BASE_PATH + '/model/first_model.pt'\n",
    "\n",
    "import preprocessing\n",
    "import read_file\n",
    "import datetime\n",
    "\n",
    "def extract_debian(text):\n",
    "    text = text.split('\\n\\n\\n')\n",
    "    header = text[0].split('\\n')\n",
    "    body = text[1]\n",
    "    sender = header[2].split(':')[1].split('<')[0]\n",
    "#     print('Sender',sender)\n",
    "#     print('Body \\n',body)\n",
    "    return sender,body\n",
    "\n",
    "def clean_debian(temp):\n",
    "    temp = re.sub('\\n+','\\n',temp)\n",
    "    temp = re.sub('\\n',' ',temp)\n",
    "    temp = re.sub('\\t',' ',temp)\n",
    "    temp = re.sub(' +',' ',temp)\n",
    "    return temp\n",
    "\n",
    "def deb_lemmatize(doc):        \n",
    "    doc = nlp(doc)\n",
    "    article, skl_texts = '',''\n",
    "    for w in doc:\n",
    "        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            article += \" \" + w.lemma_\n",
    "        if w.text == '\\n':                \n",
    "            skl_texts += \" \" + article\n",
    "            article = ''       \n",
    "    return skl_texts\n",
    "\n",
    "def deb_toppostremoval(temp):\n",
    "    strings = temp.splitlines()\n",
    "    temp = ''\n",
    "    for st in strings:\n",
    "        st = st.strip()\n",
    "        if len(st)>0:\n",
    "            if st[0]=='>':\n",
    "                continue\n",
    "            else:\n",
    "                temp += '\\n' + st\n",
    "    return temp\n",
    "\n",
    "df = pd.DataFrame()\n",
    "folder = glob.glob(folder_path)\n",
    "obj = preprocessing.preprocess()\n",
    "count_file = 0\n",
    "thread_list=[]\n",
    "try:\n",
    "    for fol in tqdm_notebook(folder):\n",
    "        files = glob.glob(fol+'/*.txt')\n",
    "        threads = []\n",
    "        for file in files:\n",
    "            ob = read_file.file_content(file)\n",
    "            ob.read_file_content()\n",
    "            threads.append(ob.mail)\n",
    "            count_file += 1\n",
    "        sorted_threads = sorted(threads, key=lambda ke: datetime.datetime.strptime(ke['Date'],'%a, %d %b %Y %H:%M:%S %z'))\n",
    "        thread_list.append(sorted_threads)\n",
    "except:\n",
    "    print(fol)\n",
    "print(len(thread_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"/home/parth/BE_Project/InferSent/infersent1.pkl\"\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "infermodel = InferSent(params_model)\n",
    "infermodel.load_state_dict(torch.load(MODEL_PATH))\n",
    "use_cuda = False\n",
    "infermodel = infermodel.cuda() if use_cuda else infermodel\n",
    "W2V_PATH = '/home/parth/BE_Project/glove.6B/glove.6B.300d.txt'\n",
    "#replace with glove.840B.300d.txt\n",
    "infermodel.set_w2v_path(W2V_PATH)\n",
    "infermodel.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi PRON would like try LZ compress index file var lib apt list APT release series start October release Ubuntu artful This swap default AcquiregzipIndexes false true On system compress var lib apt list GB MB lot space There package break I start mass bug file Debian purpose I not equivalent codesearch.d.n Ubuntu I not search I hope package especially compress index come Ubuntu place The Debian bug \n",
      " On Tue Dec Ben Hutchings write The infrastructure tool good maintain huge numb list Alex\n",
      " On Thu Sep PM  Guido Günther write I confirm I remember time I source.chanegs alongside  arch.changes reason source change miss I pbuilder cowbuilder git buildpackage Do I need add specific option need Kind regard Andreas \n",
      " Package wnpp Owner Hilko Bengen   Severity wishlist Control block  Package node gulp Version Upstream Author Rob Richardson \n",
      " Package wnpp Severity wishlist Owner Fabian Greffrath   Package font comic neue Version Upstream Author Craig Rozynski URL \n",
      " On Tue Dec Anton Gladky write We not want maintainter list l.d.o\n",
      "[Timestamp('2017-07-10 10:30:40+0530', tz='UTC+05:30'), Timestamp('2017-07-10 10:08:43+0200', tz='UTC+02:00'), Timestamp('2017-07-10 14:02:50+0530', tz='UTC+05:30'), Timestamp('2017-04-07 21:08:34+0200', tz='UTC+02:00'), Timestamp('2017-04-08 09:46:35+0200', tz='UTC+02:00'), Timestamp('2017-06-15 20:48:13-0300', tz='UTC-03:00'), Timestamp('2017-06-15 20:30:33-0700', tz='UTC-07:00'), Timestamp('2017-06-25 16:05:09+0200', tz='UTC+02:00'), Timestamp('2017-06-25 17:42:23+0200', tz='UTC+02:00'), Timestamp('2017-07-15 22:24:14+0200', tz='UTC+02:00'), Timestamp('2017-04-26 22:25:24-0500', tz='UTC-05:00'), Timestamp('2017-04-27 12:04:08+0800', tz='UTC+08:00'), Timestamp('2017-04-26 23:27:02-0500', tz='UTC-05:00'), Timestamp('2017-04-01 00:00:35+1100', tz='UTC+11:00'), Timestamp('2017-03-31 15:48:38+0200', tz='UTC+02:00'), Timestamp('2017-04-02 08:27:17+0300', tz='UTC+03:00'), Timestamp('2017-07-17 08:32:27+0530', tz='UTC+05:30'), Timestamp('2017-07-17 05:59:14+0200', tz='UTC+02:00'), Timestamp('2017-07-19 23:15:49+0200', tz='UTC+02:00'), Timestamp('2017-07-24 23:30:53+0300', tz='UTC+03:00'), Timestamp('2017-07-24 21:46:27+0100', tz='UTC+01:00'), Timestamp('2017-07-25 00:56:05+0300', tz='UTC+03:00'), Timestamp('2017-06-06 09:13:55+0100', tz='UTC+01:00'), Timestamp('2017-06-06 10:42:21+0200', tz='UTC+02:00'), Timestamp('2017-06-06 19:44:45-0400', tz='UTC-04:00'), Timestamp('2017-06-14 08:41:32+0100', tz='UTC+01:00'), Timestamp('2017-06-18 12:14:03+0100', tz='UTC+01:00'), Timestamp('2017-06-19 08:51:21+0100', tz='UTC+01:00'), Timestamp('2017-04-12 15:09:53+0200', tz='UTC+02:00'), Timestamp('2017-04-12 22:04:17+0800', tz='UTC+08:00'), Timestamp('2017-04-12 16:44:34+0100', tz='UTC+01:00'), Timestamp('2017-04-21 09:28:50+0200', tz='UTC+02:00'), Timestamp('2017-04-21 09:52:08+0200', tz='UTC+02:00'), Timestamp('2017-06-05 13:12:11-0400', tz='UTC-04:00'), Timestamp('2017-06-06 13:10:46+0800', tz='UTC+08:00'), Timestamp('2017-06-05 13:49:42+0200', tz='UTC+02:00'), Timestamp('2017-06-05 20:33:34+0800', tz='UTC+08:00'), Timestamp('2017-06-05 13:50:33+0100', tz='UTC+01:00'), Timestamp('2017-04-16 08:56:39+0200', tz='UTC+02:00'), Timestamp('2017-04-17 22:42:13+0100', tz='UTC+01:00'), Timestamp('2017-04-18 11:35:14+0800', tz='UTC+08:00'), Timestamp('2017-07-12 08:38:36+0000', tz='UTC'), Timestamp('2017-07-12 17:35:03+0200', tz='UTC+02:00'), Timestamp('2017-04-19 23:36:30+0200', tz='UTC+02:00'), Timestamp('2017-04-20 00:41:53+0200', tz='UTC+02:00'), Timestamp('2017-04-20 11:09:07+0200', tz='UTC+02:00')]\n",
      "6\n",
      "92\n",
      "1008\n",
      "23\n",
      "37\n",
      "{'\"Adam D. Barratt\"': 29,\n",
      " 'Adam Borowski': 21,\n",
      " 'Adrian Bunk': 15,\n",
      " 'Afif Elghraoui': 28,\n",
      " 'Alexander Wirt': 2,\n",
      " 'Andreas Tille': 4,\n",
      " 'Ansgar Burchardt': 34,\n",
      " 'Anton Gladky': 3,\n",
      " 'Bastien ROUCARIES': 47,\n",
      " 'Ben Hutchings': 38,\n",
      " 'Carsten Schoenert': 10,\n",
      " 'Chris Lamb': 25,\n",
      " 'Christian Seiler': 48,\n",
      " 'Colin Ian King': 30,\n",
      " 'Dmitry Bogatov': 22,\n",
      " 'Evgeni Golov': 43,\n",
      " 'Fabian Greffrath': 35,\n",
      " 'Florian Lohoff': 7,\n",
      " 'Geert Stappers': 23,\n",
      " 'Ghislain Vaillant': 26,\n",
      " 'Hans': 41,\n",
      " 'Henrique de Moraes Holschuh': 13,\n",
      " 'Hilko Bengen': 12,\n",
      " 'Holger Levsen': 46,\n",
      " 'Ian Jackson': 42,\n",
      " 'Jeremy Bicha': 45,\n",
      " 'Joerg Jaspert': 11,\n",
      " 'Jonas Smedegaard': 27,\n",
      " 'Jonathan Dowland': 44,\n",
      " 'Julian Andres Klode': 1,\n",
      " 'Marc Haber': 17,\n",
      " 'Marvin Renich': 36,\n",
      " 'Michael Stapelberg': 33,\n",
      " 'Nikolaus Rath': 9,\n",
      " 'Ole Streicher': 39,\n",
      " 'Paul Gevers': 16,\n",
      " 'Paul Wise': 19,\n",
      " 'Pavlo Solntsev': 18,\n",
      " 'Philipp Hahn': 31,\n",
      " 'Philipp Kern': 6,\n",
      " 'Pirate Praveen': 5,\n",
      " 'Russ Allbery': 14,\n",
      " 'Steve McIntyre': 32,\n",
      " 'Stuart Prescott': 20,\n",
      " 'Thibaut Paumard': 40,\n",
      " 'Vincent Bernat': 37,\n",
      " 'Wouter Verhelst': 8,\n",
      " 'shirish शिरीष': 24}\n"
     ]
    }
   ],
   "source": [
    "df_trn = pd.DataFrame()\n",
    "df_tst = pd.DataFrame()\n",
    "split_date = datetime.datetime.strptime('01 Sep 2017 23:01:14 +0000', '%d %b %Y %H:%M:%S %z')\n",
    "\n",
    "users = []\n",
    "dates  = []\n",
    "trn_dates = []\n",
    "tst_dates = []\n",
    "trn_users = []\n",
    "tst_users = []\n",
    "th_no = 0\n",
    "cnt = 0\n",
    "for thr in thread_list:\n",
    "    start_date = \"\"\n",
    "    flag = 0\n",
    "    t = ''\n",
    "    for mail in thr:\n",
    "        temp = ''\n",
    "        sender = mail['From'].split('<')[0].strip()\n",
    "        temp   = mail['content']\n",
    "        temp = deb_toppostremoval(temp)\n",
    "        temp = deb_lemmatize(temp)\n",
    "        temp = clean_debian(temp)\n",
    "        if temp == '':\n",
    "            cnt += 1\n",
    "            continue\n",
    "        users.append(sender)\n",
    "        #dates.append(datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z'))\n",
    "        temp = obj.replace_tokens(temp)\n",
    "\n",
    "        if flag==0:\n",
    "            start_date = datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z')\n",
    "            if start_date > split_date:\n",
    "                print(temp)\n",
    "                df_tst = df_tst.append({'body': str(temp),'replier':sender, 'thread_no':th_no, 'start_date':start_date, 'cur_date':start_date}, ignore_index=True)\n",
    "                #tst_users.append(sender)\n",
    "                #tst_dates.append(start_date)\n",
    "            else:\n",
    "                df_trn = df_trn.append({'body': str(temp),'replier':sender, 'thread_no':th_no, 'start_date':start_date, 'cur_date':start_date}, ignore_index=True)\n",
    "                #trn_users.append(sender)\n",
    "                #trn_dates.append(start_date)\n",
    "            t = temp\n",
    "            flag = 1\n",
    "            continue\n",
    "\n",
    "        \n",
    "        df = df.append({'body': str(t),'replier':sender, 'thread_no':th_no, 'start_date':start_date, 'cur_date':datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z')}, ignore_index=True)\n",
    "\n",
    "        if start_date <= split_date:\n",
    "            t = t + temp\n",
    "            df_trn = df_trn.append({'body': str(t),'replier':sender, 'thread_no':th_no, 'start_date':start_date, 'cur_date':datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z')}, ignore_index=True)\n",
    "            #trn_users.append(sender)\n",
    "            #trn_dates.append(datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z'))\n",
    "        else:\n",
    "            df_tst = df_tst.append({'body': str(temp),'replier':sender, 'thread_no':th_no, 'start_date':start_date, 'cur_date':datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z')}, ignore_index=True)\n",
    "            #tst_users.append(sender)\n",
    "            #tst_dates.append(datetime.datetime.strptime(mail['Date'],'%a, %d %b %Y %H:%M:%S %z'))\n",
    "\n",
    "        \n",
    "        #t = t + temp\n",
    "    th_no += 1\n",
    "    \n",
    "\n",
    "trn_users = list(df_trn.groupby(\"thread_no\", as_index=False)['replier'].apply(lambda x: x.iloc[:-1]))\n",
    "#print(trn_users)\n",
    "tst_users = list(df_tst.groupby(\"thread_no\", as_index=False)['replier'].apply(lambda x: x.iloc[:-1]))\n",
    "#print(tst_users)\n",
    "trn_dates = list(df_trn.groupby(\"thread_no\", as_index=False)['cur_date'].apply(lambda x: x.iloc[:-1]))\n",
    "print(trn_dates)\n",
    "tst_dates = list(df_tst.groupby(\"thread_no\", as_index=False)['cur_date'].apply(lambda x: x.iloc[:-1]))\n",
    "#print(tst_dates)\n",
    "\n",
    "print(cnt)\n",
    "print(count_file)\n",
    "print(len(df['body']))\n",
    "print(len(df['thread_no'].unique()))\n",
    "print(len(df['replier'].unique()))\n",
    "#print(len(dates))\n",
    "#print(len(trn_dates))\n",
    "#print(len(tst_dates))\n",
    "#print(len(users))\n",
    "#print(len(df['embeddings'][0]))\n",
    "rep_to_index = {}\n",
    "index = 0\n",
    "for rep in users:\n",
    "    if rep_to_index.get(rep, 0) == 0:\n",
    "        rep_to_index[rep] = index\n",
    "        index += 1\n",
    "pprint(rep_to_index)\n",
    "\n",
    "\n",
    "for rep in df_trn['replier']:\n",
    "    df_trn.loc[df_trn['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "#print(df_trn.head)    \n",
    "\n",
    "for rep in df_tst['replier']:\n",
    "    df_tst.loc[df_tst['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "\n",
    "for rep in df['replier']:\n",
    "    df.loc[df['replier']==rep,'int_replier'] = rep_to_index[rep]\n",
    "        \n",
    "\n",
    "df_tst['replier'] = df_tst.groupby('thread_no')['replier'].shift(-1)\n",
    "df_tst['int_replier'] = df_tst.groupby('thread_no')['int_replier'].shift(-1)\n",
    "\n",
    "df_trn['replier'] = df_trn.groupby('thread_no')['replier'].shift(-1)\n",
    "df_trn['int_replier'] = df_trn.groupby('thread_no')['int_replier'].shift(-1)\n",
    "\n",
    "df_tst.dropna(inplace=True)\n",
    "df_trn.dropna(inplace=True)\n",
    "\n",
    "df_trn.to_csv(file_name)\n",
    "df_tst.to_csv(file_name1)\n",
    "df.to_csv(file_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing of words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter()\n",
    "for sent in df_trn.body.values:\n",
    "    words.update(w.text.lower() for w in nlp(sent))\n",
    "# print(words)\n",
    "\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "#print(words)\n",
    "words = ['_PAD','_UNK'] + words\n",
    "\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "def indexer(s):\n",
    "#     vec = []\n",
    "#     for wr in nlp(s):\n",
    "#         wr = wr.text.lower()\n",
    "#         if wr in word2idx:\n",
    "#             vec.append(word2idx[wr])\n",
    "#         else:\n",
    "#             vec.append(word2idx['_PAD'])\n",
    "#     return vec\n",
    "    embedding =infermodel.encode( str(s), bsize=1, tokenize=False, verbose=True)\n",
    "    sent_vec =[]\n",
    "    numw = 0\n",
    "    for w in embedding:\n",
    "        try:\n",
    "            if numw == 0:\n",
    "                sent_vec = w\n",
    "            else:\n",
    "                sent_vec = np.add(sent_vec, w)\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    v = np.asarray(sent_vec) / numw\n",
    "    #             print(v.shape)\n",
    "    #             print(v)\n",
    "    v=np.transpose(v)\n",
    "    #             print(v.shape)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Vector - construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold = sys.maxsize)\n",
    "user_indices = []\n",
    "trn_user_indices = []\n",
    "tst_user_indices = []\n",
    "\n",
    "for u in users:\n",
    "    user_indices.append(rep_to_index[u])\n",
    "\n",
    "for v in trn_users:\n",
    "    trn_user_indices.append(rep_to_index[v])\n",
    "\n",
    "for w in tst_users:\n",
    "    tst_user_indices.append(rep_to_index[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vec_len = max(user_indices) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "46\n",
      "46\n",
      "46\n",
      "11283.0\n",
      "0.0\n",
      "12730.0\n",
      "0.0\n",
      "45481.0\n",
      "0.0\n",
      "13340.0\n",
      "0.0\n",
      "5834.0\n",
      "0.0\n",
      "1750745.0\n",
      "0.0\n",
      "2324.0\n",
      "0.0\n",
      "3698.0\n",
      "0.0\n",
      "2883.0\n",
      "0.0\n",
      "145602.0\n",
      "0.0\n",
      "3407.0\n",
      "0.0\n",
      "238402.0\n",
      "0.0\n",
      "934.0\n",
      "0.0\n",
      "5112.0\n",
      "0.0\n",
      "1706.0\n",
      "0.0\n",
      "55850.0\n",
      "0.0\n",
      "358351.0\n",
      "0.0\n",
      "432589.0\n",
      "0.0\n",
      "3264.0\n",
      "0.0\n",
      "9281.0\n",
      "0.0\n",
      "1398.0\n",
      "0.0\n",
      "43115.0\n",
      "0.0\n",
      "2632.0\n",
      "0.0\n",
      "3651.0\n",
      "0.0\n",
      "139534.0\n",
      "0.0\n",
      "160715.0\n",
      "0.0\n",
      "24987.0\n",
      "0.0\n",
      "3923.0\n",
      "0.0\n",
      "41557.0\n",
      "0.0\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  1.]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "indexx=0\n",
    "weight_list = []\n",
    "print(len(trn_dates))\n",
    "print(len(trn_users))\n",
    "print(df_trn.thread_no.shape[0])\n",
    "print(len(trn_user_indices))\n",
    "\n",
    "thread_no_list = list(df_trn['thread_no'])\n",
    "\n",
    "for i in range(0, len(df_trn.groupby(\"thread_no\"))):\n",
    "    temp_index=indexx\n",
    "    thread_start_date = trn_dates[temp_index].to_pydatetime()\n",
    "    array  = np.zeros(user_vec_len)\n",
    "    if temp_index < df_trn.thread_no.shape[0]:\n",
    "        for j in range(temp_index, temp_index + list(df_trn.thread_no).count(thread_no_list[temp_index])):\n",
    "            if j>temp_index:\n",
    "                cur_date = trn_dates[j].to_pydatetime()\n",
    "                date_diff = cur_date - thread_start_date\n",
    "                total_seconds = date_diff.total_seconds()\n",
    "                print(str(total_seconds))\n",
    "                decay_value = math.exp(-total_seconds)\n",
    "                print(str(decay_value))\n",
    "            array[trn_user_indices[j]] = 1\n",
    "            weight_list.append(list(array))\n",
    "            indexx+=1\n",
    "\n",
    "trn_weights = np.array(weight_list)\n",
    "print(trn_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "indexx=0\n",
    "weight_list = []\n",
    "print(len(tst_users))\n",
    "print(len(tst_dates))\n",
    "print(df_tst.shape[0])\n",
    "for i in range(0, df_tst.shape[0]):\n",
    "    temp_index=indexx\n",
    "    array  = np.zeros(user_vec_len)\n",
    "    for j in range(temp_index, temp_index + list(df_tst.thread_no).count(i)):\n",
    "        array[tst_user_indices[j]] += 1\n",
    "        weight_list.append(list(array))\n",
    "        indexx+=1\n",
    "\n",
    "tst_weights = np.array(weight_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding |> flag\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path, maxlen=10, calc_maxlen = False):\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "        self.df['body'] = self.df.body.apply(lambda x: x.strip())\n",
    "        print('Indexing...')\n",
    "        self.df['bodyidx'] = self.df.body.apply(indexer)\n",
    "        print('Calculating lengths')\n",
    "        self.df['lengths'] = self.df.bodyidx.apply(len)\n",
    "        if calc_maxlen == True:\n",
    "            self.maxlen = max(self.df['lengths'])\n",
    "        else:\n",
    "            self.maxlen = maxlen\n",
    "        print(self.maxlen)\n",
    "        print('Padding')\n",
    "        self.df['bodypadded'] = self.df.bodyidx.apply(self.pad_data)\n",
    "        print(self.df)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.bodypadded[idx]\n",
    "        lens = self.df.lengths[idx]\n",
    "        y = self.df.int_replier[idx]\n",
    "        e=self.df.embeddings[idx]\n",
    "        return X,y,lens,e\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing...\n",
      "Nb words kept : 400/1133 (35.3%)\n",
      "Speed : 93.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 400/1133 (35.3%)\n",
      "Speed : 96.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 400/1133 (35.3%)\n",
      "Speed : 91.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 93.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 90.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 90.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 65/181 (35.9%)\n",
      "Speed : 90.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 439/1243 (35.3%)\n",
      "Speed : 92.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 767/2169 (35.4%)\n",
      "Speed : 92.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 576/1628 (35.4%)\n",
      "Speed : 92.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1820/5171 (35.2%)\n",
      "Speed : 92.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 221/627 (35.2%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 221/627 (35.2%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 90.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 93.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 91.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 190/545 (34.9%)\n",
      "Speed : 92.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 796/2270 (35.1%)\n",
      "Speed : 92.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 583/1663 (35.1%)\n",
      "Speed : 92.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 960/2731 (35.2%)\n",
      "Speed : 92.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1080/3067 (35.2%)\n",
      "Speed : 94.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 484/1378 (35.1%)\n",
      "Speed : 93.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 713/2024 (35.2%)\n",
      "Speed : 91.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 971/2754 (35.3%)\n",
      "Speed : 96.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 143/404 (35.4%)\n",
      "Speed : 94.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 409/1143 (35.8%)\n",
      "Speed : 92.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 505/1410 (35.8%)\n",
      "Speed : 92.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 468/1334 (35.1%)\n",
      "Speed : 92.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 538/1532 (35.1%)\n",
      "Speed : 92.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 582/1655 (35.2%)\n",
      "Speed : 93.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 731/2085 (35.1%)\n",
      "Speed : 92.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 752/2144 (35.1%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1202/3420 (35.1%)\n",
      "Speed : 93.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 405/1156 (35.0%)\n",
      "Speed : 92.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 734/2097 (35.0%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 961/2743 (35.0%)\n",
      "Speed : 93.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 219/614 (35.7%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 477/1342 (35.5%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 922/2600 (35.5%)\n",
      "Speed : 93.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 117/336 (34.8%)\n",
      "Speed : 91.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 191/544 (35.1%)\n",
      "Speed : 92.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 252/715 (35.2%)\n",
      "Speed : 92.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 194/553 (35.1%)\n",
      "Speed : 90.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 333/949 (35.1%)\n",
      "Speed : 90.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 91.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 92.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 236/672 (35.1%)\n",
      "Speed : 91.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 630/1789 (35.2%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 90.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 91.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 91.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 486/1376 (35.3%)\n",
      "Speed : 92.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 537/1517 (35.4%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 654/1847 (35.4%)\n",
      "Speed : 93.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 195/551 (35.4%)\n",
      "Speed : 92.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 327/907 (36.1%)\n",
      "Speed : 92.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 423/1177 (35.9%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 306/864 (35.4%)\n",
      "Speed : 92.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 508/1433 (35.5%)\n",
      "Speed : 92.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 120/343 (35.0%)\n",
      "Speed : 91.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1226/3492 (35.1%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1391/3956 (35.2%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 400/1133 (35.3%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 400/1133 (35.3%)\n",
      "Speed : 92.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 400/1133 (35.3%)\n",
      "Speed : 91.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 90.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 91.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 91.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 65/181 (35.9%)\n",
      "Speed : 91.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 439/1243 (35.3%)\n",
      "Speed : 92.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 767/2169 (35.4%)\n",
      "Speed : 92.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 576/1628 (35.4%)\n",
      "Speed : 91.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1820/5171 (35.2%)\n",
      "Speed : 92.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 221/627 (35.2%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 221/627 (35.2%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 91.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 91.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 91.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 190/545 (34.9%)\n",
      "Speed : 91.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 796/2270 (35.1%)\n",
      "Speed : 92.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 583/1663 (35.1%)\n",
      "Speed : 93.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 960/2731 (35.2%)\n",
      "Speed : 93.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1080/3067 (35.2%)\n",
      "Speed : 93.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 484/1378 (35.1%)\n",
      "Speed : 97.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 713/2024 (35.2%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 971/2754 (35.3%)\n",
      "Speed : 97.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 143/404 (35.4%)\n",
      "Speed : 96.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 409/1143 (35.8%)\n",
      "Speed : 97.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 505/1410 (35.8%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 468/1334 (35.1%)\n",
      "Speed : 96.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 538/1532 (35.1%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 582/1655 (35.2%)\n",
      "Speed : 94.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 731/2085 (35.1%)\n",
      "Speed : 93.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 752/2144 (35.1%)\n",
      "Speed : 91.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1202/3420 (35.1%)\n",
      "Speed : 91.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 405/1156 (35.0%)\n",
      "Speed : 97.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 734/2097 (35.0%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 961/2743 (35.0%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 219/614 (35.7%)\n",
      "Speed : 97.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 477/1342 (35.5%)\n",
      "Speed : 97.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 922/2600 (35.5%)\n",
      "Speed : 94.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 117/336 (34.8%)\n",
      "Speed : 96.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 191/544 (35.1%)\n",
      "Speed : 97.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 252/715 (35.2%)\n",
      "Speed : 97.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 194/553 (35.1%)\n",
      "Speed : 96.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 333/949 (35.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 97.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 97.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 97.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 97.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 236/672 (35.1%)\n",
      "Speed : 97.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 630/1789 (35.2%)\n",
      "Speed : 97.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 96.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 96.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 96.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 486/1376 (35.3%)\n",
      "Speed : 97.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 537/1517 (35.4%)\n",
      "Speed : 97.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 654/1847 (35.4%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 195/551 (35.4%)\n",
      "Speed : 97.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 327/907 (36.1%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 423/1177 (35.9%)\n",
      "Speed : 97.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 306/864 (35.4%)\n",
      "Speed : 95.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 508/1433 (35.5%)\n",
      "Speed : 92.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 120/343 (35.0%)\n",
      "Speed : 92.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1226/3492 (35.1%)\n",
      "Speed : 97.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1391/3956 (35.2%)\n",
      "Speed : 97.8 sentences/s (cpu mode, bsize=1)\n",
      "Calculating lengths\n",
      "4096\n",
      "Padding\n",
      "     Unnamed: 0                                               body  \\\n",
      "0             0  Hi PRON would like try LZ compress index file ...   \n",
      "1             1  Hi PRON would like try LZ compress index file ...   \n",
      "2             2  Hi PRON would like try LZ compress index file ...   \n",
      "3             3  On Tue Dec Ben Hutchings write The infrastruct...   \n",
      "4             4  On Tue Dec Ben Hutchings write The infrastruct...   \n",
      "5             5  On Tue Dec Ben Hutchings write The infrastruct...   \n",
      "6             6  Moving devel On   AM Adam D. Barratt write Hi ...   \n",
      "7             7  Moving devel On   AM Adam D. Barratt write Hi ...   \n",
      "8             8  Moving devel On   AM Adam D. Barratt write Hi ...   \n",
      "9             9  On Thu Apr PM  Nikolaus Rath write I IBM Lenov...   \n",
      "10           10  On Thu Apr PM  Nikolaus Rath write I IBM Lenov...   \n",
      "11           11  On Thu Sep PM  Guido Günther write I confirm I...   \n",
      "12           12  On Thu Sep PM  Guido Günther write I confirm I...   \n",
      "13           13  Package wnpp Owner Hilko Bengen   Severity wis...   \n",
      "14           14  Package wnpp Owner Hilko Bengen   Severity wis...   \n",
      "15           15  Package wnpp Owner Hilko Bengen   Severity wis...   \n",
      "16           16  On Thu Jun write lzip available Debian experim...   \n",
      "17           17  On Thu Jun write lzip available Debian experim...   \n",
      "18           18  Hi Debian developer This e mail mean maintaine...   \n",
      "19           19  Hi Debian developer This e mail mean maintaine...   \n",
      "20           20  Hi Debian developer This e mail mean maintaine...   \n",
      "21           21  Dearend I need advice development Debian I use...   \n",
      "22           22  Dearend I need advice development Debian I use...   \n",
      "23           23  Dearend I need advice development Debian I use...   \n",
      "24           24  Package wnpp Severity wishlist Owner Stuart Pr...   \n",
      "25           25  Package wnpp Severity wishlist Owner Stuart Pr...   \n",
      "26           26  Package wnpp Severity wishlist Owner Stuart Pr...   \n",
      "27           27  Dear While I love love alioth I know probably ...   \n",
      "28           28  Dear While I love love alioth I know probably ...   \n",
      "29           29  Dear While I love love alioth I know probably ...   \n",
      "..          ...                                                ...   \n",
      "96           96  On Tue   Afif Elghraoui write Given Python pac...   \n",
      "97           97  On Tue   Afif Elghraoui write Given Python pac...   \n",
      "98           98  On Tue   Afif Elghraoui write Given Python pac...   \n",
      "99           99  Hi On  Colin King write What intent upload If ...   \n",
      "100         100  Hi On  Colin King write What intent upload If ...   \n",
      "101         101  Hi On  Colin King write What intent upload If ...   \n",
      "102         102  Hello database source)packages version release...   \n",
      "103         103  Hello database source)packages version release...   \n",
      "104         104  Hello database source)packages version release...   \n",
      "105         105  Hey pabs ’s current status AFAICT mention want...   \n",
      "106         106  Hey pabs ’s current status AFAICT mention want...   \n",
      "107         107  Package wnpp Severity wishlist Owner Fabian Gr...   \n",
      "108         108  Package wnpp Severity wishlist Owner Fabian Gr...   \n",
      "109         109  Package wnpp Severity wishlist Owner Fabian Gr...   \n",
      "110         110  You suggest nonsense However use term root beg...   \n",
      "111         111  You suggest nonsense However use term root beg...   \n",
      "112         112  On Tue Dec Anton Gladky write We not want main...   \n",
      "113         113  On Tue Dec Anton Gladky write We not want main...   \n",
      "114         114  On Tue Dec Anton Gladky write We not want main...   \n",
      "115         115  Dear developer I know debian freeze But actual...   \n",
      "116         116  Dear developer I know debian freeze But actual...   \n",
      "117         117  Dear developer I know debian freeze But actual...   \n",
      "118         118  Hi On Sat Mar PM  Jeremy Bicha write Why retir...   \n",
      "119         119  Hi On Sat Mar PM  Jeremy Bicha write Why retir...   \n",
      "120         120  Hi On Sat Mar PM  Jeremy Bicha write Why retir...   \n",
      "121         121  On Tue Jul AM  Don Armstrong write need sudo i...   \n",
      "122         122  On Tue Jul AM  Don Armstrong write need sudo i...   \n",
      "123         123  Package wnpp Severity wishlist Owner X Debbugs...   \n",
      "124         124  Package wnpp Severity wishlist Owner X Debbugs...   \n",
      "125         125  Package wnpp Severity wishlist Owner X Debbugs...   \n",
      "\n",
      "                                            embeddings              replier  \\\n",
      "0    [ 0.00213434  0.00044442  0.03167278 ... -0.02...  Julian Andres Klode   \n",
      "1    [ 0.00225739 -0.00190113  0.03217939 ... -0.02...  Julian Andres Klode   \n",
      "2    [ 0.0029889  -0.00341548  0.03379022 ... -0.02...  Julian Andres Klode   \n",
      "3    [ 0.00731797 -0.01028567  0.03043364 ... -0.02...       Alexander Wirt   \n",
      "4    [ 0.00597156 -0.00840014  0.0287723  ... -0.02...         Anton Gladky   \n",
      "5    [ 0.00099615 -0.00785118  0.02526671 ... -0.02...        Andreas Tille   \n",
      "6    [ 0.00352116 -0.00420182  0.03199914 ... -0.02...         Philipp Kern   \n",
      "7    [ 0.00176786 -0.00056188  0.02697148 ... -0.02...       Pirate Praveen   \n",
      "8    [-0.00011023  0.00324427  0.02605476 ... -0.02...         Philipp Kern   \n",
      "9    [ 0.00269352 -0.00359295  0.03128224 ... -0.02...      Wouter Verhelst   \n",
      "10   [ 0.001944   -0.0085778   0.02631017 ... -0.03...        Nikolaus Rath   \n",
      "11   [ 0.00404091 -0.00652479  0.02937023 ... -0.02...    Carsten Schoenert   \n",
      "12   [ 0.00371036 -0.00635975  0.03195983 ... -0.02...        Joerg Jaspert   \n",
      "13   [ 0.00326177 -0.00914941  0.0286821  ... -0.02...         Hilko Bengen   \n",
      "14   [ 0.00175623 -0.00805347  0.03039849 ... -0.02...         Hilko Bengen   \n",
      "15   [ 0.00154551 -0.00784024  0.02827326 ... -0.02...         Hilko Bengen   \n",
      "16   [-3.3603192e-05 -7.5255590e-03  3.1985682e-02 ...         Russ Allbery   \n",
      "17   [ 1.7971313e-03 -8.8566830e-03  3.1642690e-02 ...          Adrian Bunk   \n",
      "18   [ 0.00068678 -0.00465866  0.02904531 ... -0.02...           Marc Haber   \n",
      "19   [ 0.00231247 -0.0093836   0.03045165 ... -0.02...          Paul Gevers   \n",
      "20   [ 0.00086192  0.001073    0.03104067 ... -0.02...          Paul Gevers   \n",
      "21   [ 0.00254262 -0.00986637  0.03152264 ... -0.02...            Paul Wise   \n",
      "22   [ 0.00255136 -0.00190919  0.03374738 ... -0.02...       Pavlo Solntsev   \n",
      "23   [ 0.00092956 -0.00622379  0.02462861 ... -0.02...            Paul Wise   \n",
      "24   [ 0.00366313 -0.00411451  0.02866404 ... -0.03...        Adam Borowski   \n",
      "25   [ 0.0041396  -0.00348638  0.02768848 ... -0.02...       Dmitry Bogatov   \n",
      "26   [ 4.0822998e-03 -4.1582296e-03  3.4235660e-02 ...       Geert Stappers   \n",
      "27   [ 0.00783279 -0.00623335  0.0310686  ... -0.03...       Alexander Wirt   \n",
      "28   [ 0.00318427  0.00291578  0.02921071 ... -0.03...       Geert Stappers   \n",
      "29   [ 0.00490517 -0.0021583   0.0291335  ... -0.02...       Alexander Wirt   \n",
      "..                                                 ...                  ...   \n",
      "96   [ 0.00262896 -0.00637802  0.02741044 ... -0.02...     Jonas Smedegaard   \n",
      "97   [ 0.00269405 -0.00822727  0.02336686 ... -0.02...       Afif Elghraoui   \n",
      "98   [ 0.00364129 -0.00302648  0.03067737 ... -0.02...     Jonas Smedegaard   \n",
      "99   [ 3.2989604e-03 -6.2699192e-03  2.9146584e-02 ...    \"Adam D. Barratt\"   \n",
      "100  [-7.4295676e-05 -4.9106423e-03  2.7993914e-02 ...       Colin Ian King   \n",
      "101  [ 0.00039135 -0.00320082  0.02951297 ... -0.02...    \"Adam D. Barratt\"   \n",
      "102  [ 0.00749385 -0.00834201  0.02616924 ... -0.02...            Paul Wise   \n",
      "103  [ 0.00594288  0.00404312  0.03187208 ... -0.02...       Steve McIntyre   \n",
      "104  [ 0.00212994 -0.0062747   0.02135043 ... -0.03...        Joerg Jaspert   \n",
      "105  [ 0.00582067 -0.00550952  0.02785901 ... -0.02...     Ansgar Burchardt   \n",
      "106  [ 0.00437334 -0.00239893  0.03154097 ... -0.02...            Paul Wise   \n",
      "107  [ 0.00121864 -0.00754399  0.02552955 ... -0.02...        Adam Borowski   \n",
      "108  [ 0.00232176 -0.0079795   0.02203566 ... -0.02...     Fabian Greffrath   \n",
      "109  [ 0.00144171 -0.01054334  0.0283017  ... -0.03...     Fabian Greffrath   \n",
      "110  [ 0.00151307 -0.00596673  0.02958795 ... -0.02...            Paul Wise   \n",
      "111  [ 0.00204183 -0.0099694   0.03426799 ... -0.02...       Vincent Bernat   \n",
      "112  [ 0.0022026   0.00371055  0.02845688 ... -0.02...        Ben Hutchings   \n",
      "113  [ 0.00963464 -0.00586676  0.02679281 ... -0.02...        Ole Streicher   \n",
      "114  [ 9.1126456e-04 -9.1370115e-05  2.8974878e-02 ...      Thibaut Paumard   \n",
      "115  [ 3.1325691e-03 -3.1944688e-05  1.9702205e-02 ...            Paul Wise   \n",
      "116  [ 0.00431948 -0.00437281  0.02701543 ... -0.02...          Ian Jackson   \n",
      "117  [ 1.5043804e-03 -5.2126204e-03  3.2420378e-02 ...        Ben Hutchings   \n",
      "118  [ 0.00142199 -0.01249913  0.01953712 ... -0.02...     Jonathan Dowland   \n",
      "119  [ 0.00264188 -0.01458129  0.01996759 ... -0.02...            Paul Wise   \n",
      "120  [ 0.00112912 -0.00797426  0.02684821 ... -0.02...         Jeremy Bicha   \n",
      "121  [ 0.00221086 -0.00213971  0.02970131 ... -0.02...           Marc Haber   \n",
      "122  [ 0.00150154 -0.00769841  0.03199209 ... -0.02...       Vincent Bernat   \n",
      "123  [ 0.00282631 -0.00621646  0.02756112 ... -0.02...     Christian Seiler   \n",
      "124  [ 0.00429927 -0.00315112  0.02762518 ... -0.03...    Bastien ROUCARIES   \n",
      "125  [ 0.00407232 -0.001006    0.02360374 ... -0.02...     Christian Seiler   \n",
      "\n",
      "                    start_date  thread_no  int_replier  \\\n",
      "0    2017-09-09 16:48:29+02:00        0.0          1.0   \n",
      "1    2017-09-09 16:48:29+02:00        0.0          1.0   \n",
      "2    2017-09-09 16:48:29+02:00        0.0          1.0   \n",
      "3    2017-12-26 18:15:38+01:00        1.0          2.0   \n",
      "4    2017-12-26 18:15:38+01:00        1.0          3.0   \n",
      "5    2017-12-26 18:15:38+01:00        1.0          4.0   \n",
      "6    2017-07-10 10:30:40+05:30        2.0          6.0   \n",
      "7    2017-07-10 10:30:40+05:30        2.0          5.0   \n",
      "8    2017-07-10 10:30:40+05:30        2.0          6.0   \n",
      "9    2017-04-07 21:08:34+02:00        3.0          9.0   \n",
      "10   2017-04-07 21:08:34+02:00        3.0         10.0   \n",
      "11   2017-10-01 17:37:47+02:00        4.0         11.0   \n",
      "12   2017-10-01 17:37:47+02:00        4.0         13.0   \n",
      "13   2017-12-20 10:47:39+01:00        5.0         14.0   \n",
      "14   2017-12-20 10:47:39+01:00        5.0         14.0   \n",
      "15   2017-12-20 10:47:39+01:00        5.0         14.0   \n",
      "16   2017-06-15 20:48:13-03:00        6.0         17.0   \n",
      "17   2017-06-15 20:48:13-03:00        6.0         18.0   \n",
      "18   2017-06-25 16:05:09+02:00        7.0         20.0   \n",
      "19   2017-06-25 16:05:09+02:00        7.0         19.0   \n",
      "20   2017-06-25 16:05:09+02:00        7.0         19.0   \n",
      "21   2017-04-26 22:25:24-05:00        8.0         21.0   \n",
      "22   2017-04-26 22:25:24-05:00        8.0          8.0   \n",
      "23   2017-04-26 22:25:24-05:00        8.0         21.0   \n",
      "24   2017-04-01 00:00:35+11:00        9.0         23.0   \n",
      "25   2017-04-01 00:00:35+11:00        9.0         24.0   \n",
      "26   2017-04-01 00:00:35+11:00        9.0         25.0   \n",
      "27   2017-07-17 08:32:27+05:30       10.0          2.0   \n",
      "28   2017-07-17 08:32:27+05:30       10.0         25.0   \n",
      "29   2017-07-17 08:32:27+05:30       10.0          2.0   \n",
      "..                         ...        ...          ...   \n",
      "96   2017-06-06 09:13:55+01:00       12.0         29.0   \n",
      "97   2017-06-06 09:13:55+01:00       12.0         30.0   \n",
      "98   2017-06-06 09:13:55+01:00       12.0         29.0   \n",
      "99   2017-06-14 08:41:32+01:00       13.0         31.0   \n",
      "100  2017-06-14 08:41:32+01:00       13.0         32.0   \n",
      "101  2017-06-14 08:41:32+01:00       13.0         31.0   \n",
      "102  2017-04-12 15:09:53+02:00       14.0         21.0   \n",
      "103  2017-04-12 15:09:53+02:00       14.0         34.0   \n",
      "104  2017-04-12 15:09:53+02:00       14.0         13.0   \n",
      "105  2017-04-21 09:28:50+02:00       15.0         36.0   \n",
      "106  2017-04-21 09:28:50+02:00       15.0         21.0   \n",
      "107  2017-10-02 11:34:58+02:00       16.0         23.0   \n",
      "108  2017-10-02 11:34:58+02:00       16.0         37.0   \n",
      "109  2017-10-02 11:34:58+02:00       16.0         37.0   \n",
      "110  2017-06-05 13:12:11-04:00       17.0         21.0   \n",
      "111  2017-06-05 13:12:11-04:00       17.0         40.0   \n",
      "112  2017-12-26 16:02:08+01:00       18.0         41.0   \n",
      "113  2017-12-26 16:02:08+01:00       18.0         42.0   \n",
      "114  2017-12-26 16:02:08+01:00       18.0         43.0   \n",
      "115  2017-06-05 13:49:42+02:00       19.0         21.0   \n",
      "116  2017-06-05 13:49:42+02:00       19.0         45.0   \n",
      "117  2017-06-05 13:49:42+02:00       19.0         41.0   \n",
      "118  2017-04-16 08:56:39+02:00       20.0         47.0   \n",
      "119  2017-04-16 08:56:39+02:00       20.0         21.0   \n",
      "120  2017-04-16 08:56:39+02:00       20.0         48.0   \n",
      "121  2017-07-12 08:38:36+00:00       21.0         20.0   \n",
      "122  2017-07-12 08:38:36+00:00       21.0         40.0   \n",
      "123  2017-04-19 23:36:30+02:00       22.0         52.0   \n",
      "124  2017-04-19 23:36:30+02:00       22.0         51.0   \n",
      "125  2017-04-19 23:36:30+02:00       22.0         52.0   \n",
      "\n",
      "                                               bodyidx  lengths  \\\n",
      "0    [0.0032686759, -0.0071189487, 0.029508054, 0.0...     4096   \n",
      "1    [0.0032686759, -0.0071189487, 0.029508054, 0.0...     4096   \n",
      "2    [0.0032686759, -0.0071189487, 0.029508054, 0.0...     4096   \n",
      "3    [0.0026814556, -0.0061700493, 0.0300614, 0.001...     4096   \n",
      "4    [0.0026814556, -0.0061700493, 0.0300614, 0.001...     4096   \n",
      "5    [0.0026814556, -0.0061700493, 0.0300614, 0.001...     4096   \n",
      "6    [0.006486416, -0.0019865793, 0.026935732, 0.00...     4096   \n",
      "7    [0.0039578215, -0.0039040828, 0.031147886, 0.0...     4096   \n",
      "8    [0.003021319, -0.0024748265, 0.029361898, 0.00...     4096   \n",
      "9    [0.004367414, -0.0062958347, 0.031431034, 0.00...     4096   \n",
      "10   [0.0032232532, -0.0044483384, 0.031329326, 0.0...     4096   \n",
      "11   [0.004162115, -0.0007211214, 0.028046623, 0.00...     4096   \n",
      "12   [0.004162115, -0.0007211214, 0.028046623, 0.00...     4096   \n",
      "13   [0.004091899, -0.008063543, 0.030748429, 0.006...     4096   \n",
      "14   [0.004091899, -0.008063543, 0.030748429, 0.006...     4096   \n",
      "15   [0.004091899, -0.008063543, 0.030748429, 0.006...     4096   \n",
      "16   [0.0023026348, 0.00033434527, 0.032146815, 0.0...     4096   \n",
      "17   [0.0005240423, -0.0056494516, 0.032024194, 0.0...     4096   \n",
      "18   [0.0034302103, -0.0070815636, 0.028055519, 0.0...     4096   \n",
      "19   [0.00235099, -0.0061167004, 0.02848761, 0.0017...     4096   \n",
      "20   [0.0023470137, -0.006494695, 0.028626183, 0.00...     4096   \n",
      "21   [0.0014287583, -0.0034645626, 0.032959804, 0.0...     4096   \n",
      "22   [0.0017864134, -0.00553137, 0.032436423, 0.001...     4096   \n",
      "23   [0.0019896643, -0.0045689316, 0.03278479, 0.00...     4096   \n",
      "24   [0.0019704173, -0.012844521, 0.029359201, 0.00...     4096   \n",
      "25   [0.003071299, -0.0071668187, 0.028907044, 0.00...     4096   \n",
      "26   [0.0032743816, -0.006467174, 0.028675385, 0.00...     4096   \n",
      "27   [0.001849421, -0.004465979, 0.03419895, 0.0014...     4096   \n",
      "28   [0.002617969, -0.004716852, 0.033710558, 0.001...     4096   \n",
      "29   [0.0026619995, -0.0041047605, 0.033442177, 0.0...     4096   \n",
      "..                                                 ...      ...   \n",
      "96   [0.005053533, -0.005504938, 0.03122646, 0.0047...     4096   \n",
      "97   [0.0039669946, -0.0058811433, 0.029570496, 0.0...     4096   \n",
      "98   [0.0036660868, -0.0064449552, 0.028067779, 0.0...     4096   \n",
      "99   [0.0039912225, -0.008386686, 0.032380704, 0.00...     4096   \n",
      "100  [0.0036167905, -0.007241772, 0.030631412, 0.00...     4096   \n",
      "101  [0.0018353002, -0.0061166547, 0.029358497, 0.0...     4096   \n",
      "102  [0.0027506545, -0.00644225, 0.03165719, -0.001...     4096   \n",
      "103  [0.004562059, -0.0072261626, 0.02932814, 0.003...     4096   \n",
      "104  [0.004896304, -0.004498282, 0.029943958, 0.002...     4096   \n",
      "105  [0.0044591036, -0.009677137, 0.025757466, 0.00...     4096   \n",
      "106  [0.005027447, -0.007937501, 0.026634706, 0.003...     4096   \n",
      "107  [0.0036681541, -0.009050923, 0.02366214, 0.007...     4096   \n",
      "108  [0.0036681541, -0.009050923, 0.02366214, 0.007...     4096   \n",
      "109  [0.0036681541, -0.009050923, 0.02366214, 0.007...     4096   \n",
      "110  [0.0021096666, -0.0022836428, 0.031248003, 0.0...     4096   \n",
      "111  [0.0017365554, -0.004587035, 0.030209798, 0.00...     4096   \n",
      "112  [-0.0002570824, -0.0025482199, 0.024481867, 0....     4096   \n",
      "113  [-0.0002570824, -0.0025482199, 0.024481867, 0....     4096   \n",
      "114  [-0.0002570824, -0.0025482199, 0.024481867, 0....     4096   \n",
      "115  [0.0027358201, -0.00711883, 0.030019678, 0.001...     4096   \n",
      "116  [0.0027747238, -0.006413272, 0.029099904, 0.00...     4096   \n",
      "117  [0.0030482605, -0.0060682883, 0.028666476, 0.0...     4096   \n",
      "118  [0.0021044938, -0.007620677, 0.026258392, 0.00...     4096   \n",
      "119  [0.0018257664, -0.009574711, 0.023643471, 0.00...     4096   \n",
      "120  [0.0020105895, -0.010717826, 0.022732297, 0.00...     4096   \n",
      "121  [0.0014053258, -0.0037439235, 0.029122662, 0.0...     4096   \n",
      "122  [0.0017245932, -0.003045611, 0.029519152, 0.00...     4096   \n",
      "123  [0.0035361901, -0.004946637, 0.02555748, 0.002...     4096   \n",
      "124  [0.0028955056, -0.0061013615, 0.027332263, 0.0...     4096   \n",
      "125  [0.0030620196, -0.0057514026, 0.027367, 0.0044...     4096   \n",
      "\n",
      "                                            bodypadded  \n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "7    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "8    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "9    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "10   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "11   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "12   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "13   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "14   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "15   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "16   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "17   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "18   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "19   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "20   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "21   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "22   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "23   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "24   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "25   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "26   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "27   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "28   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "29   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "..                                                 ...  \n",
      "96   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "97   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "98   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "99   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "100  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "101  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "102  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "103  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "104  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "105  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "106  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "107  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "108  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "109  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "110  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "111  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "112  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "113  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "114  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "115  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "116  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "117  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "118  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "119  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "120  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "121  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "122  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "123  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "124  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "125  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "\n",
      "[126 rows x 10 columns]\n",
      "Indexing...\n",
      "Nb words kept : 65/181 (35.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 95.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 439/1243 (35.3%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 767/2169 (35.4%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 576/1628 (35.4%)\n",
      "Speed : 97.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1820/5171 (35.2%)\n",
      "Speed : 97.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 190/545 (34.9%)\n",
      "Speed : 97.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 796/2270 (35.1%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 583/1663 (35.1%)\n",
      "Speed : 97.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 960/2731 (35.2%)\n",
      "Speed : 97.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1080/3067 (35.2%)\n",
      "Speed : 97.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 484/1378 (35.1%)\n",
      "Speed : 97.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 713/2024 (35.2%)\n",
      "Speed : 95.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 971/2754 (35.3%)\n",
      "Speed : 92.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 143/404 (35.4%)\n",
      "Speed : 91.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 409/1143 (35.8%)\n",
      "Speed : 91.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 505/1410 (35.8%)\n",
      "Speed : 92.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 468/1334 (35.1%)\n",
      "Speed : 92.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 538/1532 (35.1%)\n",
      "Speed : 93.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 582/1655 (35.2%)\n",
      "Speed : 94.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 731/2085 (35.1%)\n",
      "Speed : 93.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 752/2144 (35.1%)\n",
      "Speed : 92.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1202/3420 (35.1%)\n",
      "Speed : 94.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 405/1156 (35.0%)\n",
      "Speed : 92.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 734/2097 (35.0%)\n",
      "Speed : 94.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 961/2743 (35.0%)\n",
      "Speed : 94.0 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 219/614 (35.7%)\n",
      "Speed : 91.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 477/1342 (35.5%)\n",
      "Speed : 92.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 922/2600 (35.5%)\n",
      "Speed : 93.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 117/336 (34.8%)\n",
      "Speed : 94.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 191/544 (35.1%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 252/715 (35.2%)\n",
      "Speed : 94.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 194/553 (35.1%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 333/949 (35.1%)\n",
      "Speed : 92.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 236/672 (35.1%)\n",
      "Speed : 92.9 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 630/1789 (35.2%)\n",
      "Speed : 94.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 486/1376 (35.3%)\n",
      "Speed : 94.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 537/1517 (35.4%)\n",
      "Speed : 94.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 654/1847 (35.4%)\n",
      "Speed : 94.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 195/551 (35.4%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 327/907 (36.1%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 423/1177 (35.9%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 306/864 (35.4%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 508/1433 (35.5%)\n",
      "Speed : 94.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 120/343 (35.0%)\n",
      "Speed : 94.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1226/3492 (35.1%)\n",
      "Speed : 87.6 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1391/3956 (35.2%)\n",
      "Speed : 86.1 sentences/s (cpu mode, bsize=1)\n",
      "Calculating lengths\n",
      "4096\n",
      "Padding\n",
      "    Unnamed: 0                                               body  \\\n",
      "0            0  Moving devel On   AM Adam D. Barratt write Hi ...   \n",
      "1            1  Moving devel On   AM Adam D. Barratt write Hi ...   \n",
      "2            2  Moving devel On   AM Adam D. Barratt write Hi ...   \n",
      "3            3  On Thu Apr PM  Nikolaus Rath write I IBM Lenov...   \n",
      "4            4  On Thu Apr PM  Nikolaus Rath write I IBM Lenov...   \n",
      "5            5  On Thu Jun write lzip available Debian experim...   \n",
      "6            6  On Thu Jun write lzip available Debian experim...   \n",
      "7            7  Hi Debian developer This e mail mean maintaine...   \n",
      "8            8  Hi Debian developer This e mail mean maintaine...   \n",
      "9            9  Hi Debian developer This e mail mean maintaine...   \n",
      "10          10  Dearend I need advice development Debian I use...   \n",
      "11          11  Dearend I need advice development Debian I use...   \n",
      "12          12  Dearend I need advice development Debian I use...   \n",
      "13          13  Package wnpp Severity wishlist Owner Stuart Pr...   \n",
      "14          14  Package wnpp Severity wishlist Owner Stuart Pr...   \n",
      "15          15  Package wnpp Severity wishlist Owner Stuart Pr...   \n",
      "16          16  Dear While I love love alioth I know probably ...   \n",
      "17          17  Dear While I love love alioth I know probably ...   \n",
      "18          18  Dear While I love love alioth I know probably ...   \n",
      "19          19  On Sun Jul PM  Mattia Rizzolo write What expec...   \n",
      "20          20  On Sun Jul PM  Mattia Rizzolo write What expec...   \n",
      "21          21  On Sun Jul PM  Mattia Rizzolo write What expec...   \n",
      "22          22  On Tue   Afif Elghraoui write Given Python pac...   \n",
      "23          23  On Tue   Afif Elghraoui write Given Python pac...   \n",
      "24          24  On Tue   Afif Elghraoui write Given Python pac...   \n",
      "25          25  Hi On  Colin King write What intent upload If ...   \n",
      "26          26  Hi On  Colin King write What intent upload If ...   \n",
      "27          27  Hi On  Colin King write What intent upload If ...   \n",
      "28          28  Hello database source)packages version release...   \n",
      "29          29  Hello database source)packages version release...   \n",
      "30          30  Hello database source)packages version release...   \n",
      "31          31  Hey pabs ’s current status AFAICT mention want...   \n",
      "32          32  Hey pabs ’s current status AFAICT mention want...   \n",
      "33          33  You suggest nonsense However use term root beg...   \n",
      "34          34  You suggest nonsense However use term root beg...   \n",
      "35          35  Dear developer I know debian freeze But actual...   \n",
      "36          36  Dear developer I know debian freeze But actual...   \n",
      "37          37  Dear developer I know debian freeze But actual...   \n",
      "38          38  Hi On Sat Mar PM  Jeremy Bicha write Why retir...   \n",
      "39          39  Hi On Sat Mar PM  Jeremy Bicha write Why retir...   \n",
      "40          40  Hi On Sat Mar PM  Jeremy Bicha write Why retir...   \n",
      "41          41  On Tue Jul AM  Don Armstrong write need sudo i...   \n",
      "42          42  On Tue Jul AM  Don Armstrong write need sudo i...   \n",
      "43          43  Package wnpp Severity wishlist Owner X Debbugs...   \n",
      "44          44  Package wnpp Severity wishlist Owner X Debbugs...   \n",
      "45          45  Package wnpp Severity wishlist Owner X Debbugs...   \n",
      "\n",
      "                                           embeddings            replier  \\\n",
      "0   [ 0.00352116 -0.00420182  0.03199914 ... -0.02...       Philipp Kern   \n",
      "1   [ 0.00176786 -0.00056188  0.02697148 ... -0.02...     Pirate Praveen   \n",
      "2   [-0.00011023  0.00324427  0.02605476 ... -0.02...       Philipp Kern   \n",
      "3   [ 0.00269352 -0.00359295  0.03128224 ... -0.02...    Wouter Verhelst   \n",
      "4   [ 0.001944   -0.0085778   0.02631017 ... -0.03...      Nikolaus Rath   \n",
      "5   [-3.3603192e-05 -7.5255590e-03  3.1985682e-02 ...       Russ Allbery   \n",
      "6   [ 1.7971313e-03 -8.8566830e-03  3.1642690e-02 ...        Adrian Bunk   \n",
      "7   [ 0.00068678 -0.00465866  0.02904531 ... -0.02...         Marc Haber   \n",
      "8   [ 0.00231247 -0.0093836   0.03045165 ... -0.02...        Paul Gevers   \n",
      "9   [ 0.00086192  0.001073    0.03104067 ... -0.02...        Paul Gevers   \n",
      "10  [ 0.00254262 -0.00986637  0.03152264 ... -0.02...          Paul Wise   \n",
      "11  [ 0.00255136 -0.00190919  0.03374738 ... -0.02...     Pavlo Solntsev   \n",
      "12  [ 0.00092956 -0.00622379  0.02462861 ... -0.02...          Paul Wise   \n",
      "13  [ 0.00366313 -0.00411451  0.02866404 ... -0.03...      Adam Borowski   \n",
      "14  [ 0.0041396  -0.00348638  0.02768848 ... -0.02...     Dmitry Bogatov   \n",
      "15  [ 4.0822998e-03 -4.1582296e-03  3.4235660e-02 ...     Geert Stappers   \n",
      "16  [ 0.00783279 -0.00623335  0.0310686  ... -0.03...     Alexander Wirt   \n",
      "17  [ 0.00318427  0.00291578  0.02921071 ... -0.03...     Geert Stappers   \n",
      "18  [ 0.00490517 -0.0021583   0.0291335  ... -0.02...     Alexander Wirt   \n",
      "19  [ 0.00845845 -0.01092197  0.03660526 ... -0.04...         Chris Lamb   \n",
      "20  [ 0.00481861 -0.00656976  0.03130706 ... -0.02...        Adrian Bunk   \n",
      "21  [ 0.00265151 -0.00312308  0.02776352 ... -0.02...         Chris Lamb   \n",
      "22  [ 0.00262896 -0.00637802  0.02741044 ... -0.02...   Jonas Smedegaard   \n",
      "23  [ 0.00269405 -0.00822727  0.02336686 ... -0.02...     Afif Elghraoui   \n",
      "24  [ 0.00364129 -0.00302648  0.03067737 ... -0.02...   Jonas Smedegaard   \n",
      "25  [ 3.2989604e-03 -6.2699192e-03  2.9146584e-02 ...  \"Adam D. Barratt\"   \n",
      "26  [-7.4295676e-05 -4.9106423e-03  2.7993914e-02 ...     Colin Ian King   \n",
      "27  [ 0.00039135 -0.00320082  0.02951297 ... -0.02...  \"Adam D. Barratt\"   \n",
      "28  [ 0.00749385 -0.00834201  0.02616924 ... -0.02...          Paul Wise   \n",
      "29  [ 0.00594288  0.00404312  0.03187208 ... -0.02...     Steve McIntyre   \n",
      "30  [ 0.00212994 -0.0062747   0.02135043 ... -0.03...      Joerg Jaspert   \n",
      "31  [ 0.00582067 -0.00550952  0.02785901 ... -0.02...   Ansgar Burchardt   \n",
      "32  [ 0.00437334 -0.00239893  0.03154097 ... -0.02...          Paul Wise   \n",
      "33  [ 0.00151307 -0.00596673  0.02958795 ... -0.02...          Paul Wise   \n",
      "34  [ 0.00204183 -0.0099694   0.03426799 ... -0.02...     Vincent Bernat   \n",
      "35  [ 3.1325691e-03 -3.1944688e-05  1.9702205e-02 ...          Paul Wise   \n",
      "36  [ 0.00431948 -0.00437281  0.02701543 ... -0.02...        Ian Jackson   \n",
      "37  [ 1.5043804e-03 -5.2126204e-03  3.2420378e-02 ...      Ben Hutchings   \n",
      "38  [ 0.00142199 -0.01249913  0.01953712 ... -0.02...   Jonathan Dowland   \n",
      "39  [ 0.00264188 -0.01458129  0.01996759 ... -0.02...          Paul Wise   \n",
      "40  [ 0.00112912 -0.00797426  0.02684821 ... -0.02...       Jeremy Bicha   \n",
      "41  [ 0.00221086 -0.00213971  0.02970131 ... -0.02...         Marc Haber   \n",
      "42  [ 0.00150154 -0.00769841  0.03199209 ... -0.02...     Vincent Bernat   \n",
      "43  [ 0.00282631 -0.00621646  0.02756112 ... -0.02...   Christian Seiler   \n",
      "44  [ 0.00429927 -0.00315112  0.02762518 ... -0.03...  Bastien ROUCARIES   \n",
      "45  [ 0.00407232 -0.001006    0.02360374 ... -0.02...   Christian Seiler   \n",
      "\n",
      "                   start_date  thread_no  int_replier  \\\n",
      "0   2017-07-10 10:30:40+05:30        2.0          6.0   \n",
      "1   2017-07-10 10:30:40+05:30        2.0          5.0   \n",
      "2   2017-07-10 10:30:40+05:30        2.0          6.0   \n",
      "3   2017-04-07 21:08:34+02:00        3.0          9.0   \n",
      "4   2017-04-07 21:08:34+02:00        3.0         10.0   \n",
      "5   2017-06-15 20:48:13-03:00        6.0         17.0   \n",
      "6   2017-06-15 20:48:13-03:00        6.0         18.0   \n",
      "7   2017-06-25 16:05:09+02:00        7.0         20.0   \n",
      "8   2017-06-25 16:05:09+02:00        7.0         19.0   \n",
      "9   2017-06-25 16:05:09+02:00        7.0         19.0   \n",
      "10  2017-04-26 22:25:24-05:00        8.0         21.0   \n",
      "11  2017-04-26 22:25:24-05:00        8.0          8.0   \n",
      "12  2017-04-26 22:25:24-05:00        8.0         21.0   \n",
      "13  2017-04-01 00:00:35+11:00        9.0         23.0   \n",
      "14  2017-04-01 00:00:35+11:00        9.0         24.0   \n",
      "15  2017-04-01 00:00:35+11:00        9.0         25.0   \n",
      "16  2017-07-17 08:32:27+05:30       10.0          2.0   \n",
      "17  2017-07-17 08:32:27+05:30       10.0         25.0   \n",
      "18  2017-07-17 08:32:27+05:30       10.0          2.0   \n",
      "19  2017-07-24 23:30:53+03:00       11.0         27.0   \n",
      "20  2017-07-24 23:30:53+03:00       11.0         18.0   \n",
      "21  2017-07-24 23:30:53+03:00       11.0         27.0   \n",
      "22  2017-06-06 09:13:55+01:00       12.0         29.0   \n",
      "23  2017-06-06 09:13:55+01:00       12.0         30.0   \n",
      "24  2017-06-06 09:13:55+01:00       12.0         29.0   \n",
      "25  2017-06-14 08:41:32+01:00       13.0         31.0   \n",
      "26  2017-06-14 08:41:32+01:00       13.0         32.0   \n",
      "27  2017-06-14 08:41:32+01:00       13.0         31.0   \n",
      "28  2017-04-12 15:09:53+02:00       14.0         21.0   \n",
      "29  2017-04-12 15:09:53+02:00       14.0         34.0   \n",
      "30  2017-04-12 15:09:53+02:00       14.0         13.0   \n",
      "31  2017-04-21 09:28:50+02:00       15.0         36.0   \n",
      "32  2017-04-21 09:28:50+02:00       15.0         21.0   \n",
      "33  2017-06-05 13:12:11-04:00       17.0         21.0   \n",
      "34  2017-06-05 13:12:11-04:00       17.0         40.0   \n",
      "35  2017-06-05 13:49:42+02:00       19.0         21.0   \n",
      "36  2017-06-05 13:49:42+02:00       19.0         45.0   \n",
      "37  2017-06-05 13:49:42+02:00       19.0         41.0   \n",
      "38  2017-04-16 08:56:39+02:00       20.0         47.0   \n",
      "39  2017-04-16 08:56:39+02:00       20.0         21.0   \n",
      "40  2017-04-16 08:56:39+02:00       20.0         48.0   \n",
      "41  2017-07-12 08:38:36+00:00       21.0         20.0   \n",
      "42  2017-07-12 08:38:36+00:00       21.0         40.0   \n",
      "43  2017-04-19 23:36:30+02:00       22.0         52.0   \n",
      "44  2017-04-19 23:36:30+02:00       22.0         51.0   \n",
      "45  2017-04-19 23:36:30+02:00       22.0         52.0   \n",
      "\n",
      "                                              bodyidx  lengths  \\\n",
      "0   [0.006486416, -0.0019865793, 0.026935732, 0.00...     4096   \n",
      "1   [0.0039578215, -0.0039040828, 0.031147886, 0.0...     4096   \n",
      "2   [0.003021319, -0.0024748265, 0.029361898, 0.00...     4096   \n",
      "3   [0.004367414, -0.0062958347, 0.031431034, 0.00...     4096   \n",
      "4   [0.0032232532, -0.0044483384, 0.031329326, 0.0...     4096   \n",
      "5   [0.0023026348, 0.00033434527, 0.032146815, 0.0...     4096   \n",
      "6   [0.0005240423, -0.0056494516, 0.032024194, 0.0...     4096   \n",
      "7   [0.0034302103, -0.0070815636, 0.028055519, 0.0...     4096   \n",
      "8   [0.00235099, -0.0061167004, 0.02848761, 0.0017...     4096   \n",
      "9   [0.0023470137, -0.006494695, 0.028626183, 0.00...     4096   \n",
      "10  [0.0014287583, -0.0034645626, 0.032959804, 0.0...     4096   \n",
      "11  [0.0017864134, -0.00553137, 0.032436423, 0.001...     4096   \n",
      "12  [0.0019896643, -0.0045689316, 0.03278479, 0.00...     4096   \n",
      "13  [0.0019704173, -0.012844521, 0.029359201, 0.00...     4096   \n",
      "14  [0.003071299, -0.0071668187, 0.028907044, 0.00...     4096   \n",
      "15  [0.0032743816, -0.006467174, 0.028675385, 0.00...     4096   \n",
      "16  [0.001849421, -0.004465979, 0.03419895, 0.0014...     4096   \n",
      "17  [0.002617969, -0.004716852, 0.033710558, 0.001...     4096   \n",
      "18  [0.0026619995, -0.0041047605, 0.033442177, 0.0...     4096   \n",
      "19  [0.0043211584, -0.0045862687, 0.034755703, 0.0...     4096   \n",
      "20  [0.0044446522, -0.0047544674, 0.03487276, 0.00...     4096   \n",
      "21  [0.0045826863, -0.005443142, 0.033501346, 0.00...     4096   \n",
      "22  [0.005053533, -0.005504938, 0.03122646, 0.0047...     4096   \n",
      "23  [0.0039669946, -0.0058811433, 0.029570496, 0.0...     4096   \n",
      "24  [0.0036660868, -0.0064449552, 0.028067779, 0.0...     4096   \n",
      "25  [0.0039912225, -0.008386686, 0.032380704, 0.00...     4096   \n",
      "26  [0.0036167905, -0.007241772, 0.030631412, 0.00...     4096   \n",
      "27  [0.0018353002, -0.0061166547, 0.029358497, 0.0...     4096   \n",
      "28  [0.0027506545, -0.00644225, 0.03165719, -0.001...     4096   \n",
      "29  [0.004562059, -0.0072261626, 0.02932814, 0.003...     4096   \n",
      "30  [0.004896304, -0.004498282, 0.029943958, 0.002...     4096   \n",
      "31  [0.0044591036, -0.009677137, 0.025757466, 0.00...     4096   \n",
      "32  [0.005027447, -0.007937501, 0.026634706, 0.003...     4096   \n",
      "33  [0.0021096666, -0.0022836428, 0.031248003, 0.0...     4096   \n",
      "34  [0.0017365554, -0.004587035, 0.030209798, 0.00...     4096   \n",
      "35  [0.0027358201, -0.00711883, 0.030019678, 0.001...     4096   \n",
      "36  [0.0027747238, -0.006413272, 0.029099904, 0.00...     4096   \n",
      "37  [0.0030482605, -0.0060682883, 0.028666476, 0.0...     4096   \n",
      "38  [0.0021044938, -0.007620677, 0.026258392, 0.00...     4096   \n",
      "39  [0.0018257664, -0.009574711, 0.023643471, 0.00...     4096   \n",
      "40  [0.0020105895, -0.010717826, 0.022732297, 0.00...     4096   \n",
      "41  [0.0014053258, -0.0037439235, 0.029122662, 0.0...     4096   \n",
      "42  [0.0017245932, -0.003045611, 0.029519152, 0.00...     4096   \n",
      "43  [0.0035361901, -0.004946637, 0.02555748, 0.002...     4096   \n",
      "44  [0.0028955056, -0.0061013615, 0.027332263, 0.0...     4096   \n",
      "45  [0.0030620196, -0.0057514026, 0.027367, 0.0044...     4096   \n",
      "\n",
      "                                           bodypadded  \n",
      "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "12  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "15  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "17  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "19  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "20  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "21  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "22  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "23  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "24  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "25  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "26  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "27  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "28  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "29  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "30  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "31  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "32  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "33  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "34  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "35  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "36  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "37  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "38  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "39  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "40  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "41  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "42  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "43  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "44  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "45  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "Indexing...\n",
      "Nb words kept : 400/1133 (35.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 81.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 263/743 (35.4%)\n",
      "Speed : 94.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 340/963 (35.3%)\n",
      "Speed : 95.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 88/250 (35.2%)\n",
      "Speed : 96.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 209/589 (35.5%)\n",
      "Speed : 97.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 84/238 (35.3%)\n",
      "Speed : 96.7 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 221/627 (35.2%)\n",
      "Speed : 96.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 179/509 (35.2%)\n",
      "Speed : 91.4 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 123/350 (35.1%)\n",
      "Speed : 91.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 129/367 (35.1%)\n",
      "Speed : 91.3 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 133/379 (35.1%)\n",
      "Speed : 91.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 122/348 (35.1%)\n",
      "Speed : 91.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 1076/3031 (35.5%)\n",
      "Speed : 90.2 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 129/364 (35.4%)\n",
      "Speed : 95.8 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 64/181 (35.4%)\n",
      "Speed : 96.1 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 81/227 (35.7%)\n",
      "Speed : 96.5 sentences/s (cpu mode, bsize=1)\n",
      "Nb words kept : 52/145 (35.9%)\n",
      "Speed : 95.9 sentences/s (cpu mode, bsize=1)\n",
      "Calculating lengths\n",
      "4096\n",
      "Padding\n",
      "    Unnamed: 0                                               body  \\\n",
      "0            0  Hi PRON would like try LZ compress index file ...   \n",
      "1            1  On Sat Sep PM  Julian Andres Klode write PRON ...   \n",
      "2            2  On Sat Sep PM  Julian Andres Klode write there...   \n",
      "3            4  On Tue Dec Ben Hutchings write The infrastruct...   \n",
      "4            5  On Tue Dec Simon McVittie write We happy run l...   \n",
      "5            6  GMT Alexander Wirt    skip  That OK @lists.ali...   \n",
      "6            8  On Thu Sep PM  Guido Günther write I confirm I...   \n",
      "7            9  Hi Andreas Am um  schrieb Andreas Tille Guido ...   \n",
      "8           11  Package wnpp Owner Hilko Bengen   Severity wis...   \n",
      "9           12  Package wnpp Owner Hilko Bengen   Severity wis...   \n",
      "10          13  Package wnpp Owner Hilko Bengen   Severity wis...   \n",
      "11          15  Package wnpp Severity wishlist Owner Fabian Gr...   \n",
      "12          16  On Mon Oct AM  Fabian Greffrath write Yay I lo...   \n",
      "13          17  Hi Adam Am Montag den   schrieb Adam Borowski ...   \n",
      "14          19  On Tue Dec Anton Gladky write We not want main...   \n",
      "15          20  On Tue   Alexander Wirt write Why Ben Ben Hutc...   \n",
      "16          21  Mehdi Dogguy   write I fully agree It make pag...   \n",
      "\n",
      "                                           embeddings              replier  \\\n",
      "0   [ 0.00326473 -0.00717053  0.02929869 ... -0.02...  Julian Andres Klode   \n",
      "1   [ 0.00213434  0.00044442  0.03167278 ... -0.02...  Julian Andres Klode   \n",
      "2   [ 0.00225739 -0.00190113  0.03217939 ... -0.02...  Julian Andres Klode   \n",
      "3   [ 0.00267914 -0.0062972   0.02958235 ... -0.02...       Alexander Wirt   \n",
      "4   [ 0.00731797 -0.01028567  0.03043364 ... -0.02...         Anton Gladky   \n",
      "5   [ 0.00597156 -0.00840014  0.0287723  ... -0.02...        Andreas Tille   \n",
      "6   [ 0.00414699 -0.00087148  0.02768231 ... -0.02...    Carsten Schoenert   \n",
      "7   [ 0.00404091 -0.00652479  0.02937023 ... -0.02...        Joerg Jaspert   \n",
      "8   [ 0.00406604 -0.00821431  0.03005527 ... -0.02...         Hilko Bengen   \n",
      "9   [ 0.00326177 -0.00914941  0.0286821  ... -0.02...         Hilko Bengen   \n",
      "10  [ 0.00175623 -0.00805347  0.03039849 ... -0.02...         Hilko Bengen   \n",
      "11  [ 0.00364892 -0.00918698  0.02307769 ... -0.02...        Adam Borowski   \n",
      "12  [ 0.00121864 -0.00754399  0.02552955 ... -0.02...     Fabian Greffrath   \n",
      "13  [ 0.00232176 -0.0079795   0.02203566 ... -0.02...     Fabian Greffrath   \n",
      "14  [-0.00021504 -0.00277804  0.02391178 ... -0.02...        Ben Hutchings   \n",
      "15  [ 0.0022026   0.00371055  0.02845688 ... -0.02...        Ole Streicher   \n",
      "16  [ 0.00963464 -0.00586676  0.02679281 ... -0.02...      Thibaut Paumard   \n",
      "\n",
      "                   start_date  thread_no  int_replier  \\\n",
      "0   2017-09-09 16:48:29+02:00        0.0          1.0   \n",
      "1   2017-09-09 16:48:29+02:00        0.0          1.0   \n",
      "2   2017-09-09 16:48:29+02:00        0.0          1.0   \n",
      "3   2017-12-26 18:15:38+01:00        1.0          2.0   \n",
      "4   2017-12-26 18:15:38+01:00        1.0          3.0   \n",
      "5   2017-12-26 18:15:38+01:00        1.0          4.0   \n",
      "6   2017-10-01 17:37:47+02:00        4.0         11.0   \n",
      "7   2017-10-01 17:37:47+02:00        4.0         13.0   \n",
      "8   2017-12-20 10:47:39+01:00        5.0         14.0   \n",
      "9   2017-12-20 10:47:39+01:00        5.0         14.0   \n",
      "10  2017-12-20 10:47:39+01:00        5.0         14.0   \n",
      "11  2017-10-02 11:34:58+02:00       16.0         23.0   \n",
      "12  2017-10-02 11:34:58+02:00       16.0         37.0   \n",
      "13  2017-10-02 11:34:58+02:00       16.0         37.0   \n",
      "14  2017-12-26 16:02:08+01:00       18.0         41.0   \n",
      "15  2017-12-26 16:02:08+01:00       18.0         42.0   \n",
      "16  2017-12-26 16:02:08+01:00       18.0         43.0   \n",
      "\n",
      "                                              bodyidx  lengths  \\\n",
      "0   [0.0032686759, -0.0071189487, 0.029508054, 0.0...     4096   \n",
      "1   [0.0021330395, 0.0005125976, 0.03184102, 0.004...     4096   \n",
      "2   [0.0022567485, -0.0018552961, 0.032311015, 0.0...     4096   \n",
      "3   [0.0026814556, -0.0061700493, 0.0300614, 0.001...     4096   \n",
      "4   [0.007341143, -0.0102512175, 0.030639417, 0.00...     4096   \n",
      "5   [0.0060548037, -0.008183798, 0.029756734, 0.00...     4096   \n",
      "6   [0.004162115, -0.0007211214, 0.028046623, 0.00...     4096   \n",
      "7   [0.0040496504, -0.006463554, 0.029604558, 0.00...     4096   \n",
      "8   [0.004091899, -0.008063543, 0.030748429, 0.006...     4096   \n",
      "9   [0.0032739611, -0.00902015, 0.02932173, 0.0052...     4096   \n",
      "10  [0.0017454096, -0.0079116225, 0.031044692, 0.0...     4096   \n",
      "11  [0.0036681541, -0.009050923, 0.02366214, 0.007...     4096   \n",
      "12  [0.0012174762, -0.007534746, 0.025564965, 0.00...     4096   \n",
      "13  [0.00231938, -0.007832105, 0.022572247, 0.0033...     4096   \n",
      "14  [-0.0002570824, -0.0025482199, 0.024481867, 0....     4096   \n",
      "15  [0.0021992289, 0.003972245, 0.02896343, 0.0018...     4096   \n",
      "16  [0.009909994, -0.005419843, 0.02830692, 0.0021...     4096   \n",
      "\n",
      "                                           bodypadded  \n",
      "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "12  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "13  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "14  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "15  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "16  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "ds = VectorizeData(file_name2, calc_maxlen = True)\n",
    "dtrain = VectorizeData(file_name, maxlen = ds.maxlen)\n",
    "dtest = VectorizeData(file_name1, maxlen = ds.maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Feedforward Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ds.maxlen\n",
    "hidden_size = 50\n",
    "num_classes = user_vec_len\n",
    "num_epochs = 5\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings |>\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,user_vec_len, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + user_vec_len, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x,w):\n",
    "#         x = torch.FloatTensor(x) \n",
    "        catt = torch.cat((x,w),1)\n",
    "        out = self.fc1(catt)\n",
    "        out = self.relu(out)       \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size,user_vec_len, num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " Epoch 0: Train loss: 0.0017415600140457568 acc: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " Epoch 1: Train loss: -0.03785949520280828 acc: 0.021739130434782608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " Epoch 2: Train loss: -0.09614493801137028 acc: 0.13043478260869565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " Epoch 3: Train loss: -0.24308662359481273 acc: 0.15217391304347827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " Epoch 4: Train loss: -0.7661229498360468 acc: 0.15217391304347827\n"
     ]
    }
   ],
   "source": [
    "train_dl= DataLoader(dtrain, batch_size=1)\n",
    "num_batch = len(train_dl)\n",
    "for epoch in range(num_epochs):\n",
    "    y_true_train = list()\n",
    "    y_pred_train = list()\n",
    "    total_loss_train = 0\n",
    "    t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n",
    "    for we, w in zip(t,trn_weights):\n",
    "        X = we[0]\n",
    "        y = we[1]\n",
    "        lengths = we[2]\n",
    "        \n",
    "        w = w.reshape(-1,1)\n",
    "        w = w.transpose()\n",
    "        \n",
    "        w = Variable(torch.Tensor(w).cpu())\n",
    "        X = Variable(X.cpu())\n",
    "        y = Variable(y.cpu())\n",
    "        lengths = lengths.numpy()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        X = X.float()\n",
    "        w = w.float()\n",
    "        y = y.long()\n",
    "        pred = model(X,w)\n",
    "        # F.nll_loss can be replaced with criterion\n",
    "        loss = F.nll_loss(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        t.set_postfix(loss=loss.item())\n",
    "        pred_idx = torch.max(pred, dim=1)[1]\n",
    "\n",
    "        y_true_train += list(y.cpu().data.numpy())\n",
    "        y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "        total_loss_train += loss.item()\n",
    "        \n",
    "\n",
    "    train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_loss = total_loss_train/len(train_dl)\n",
    "    print(f' Epoch {epoch}: Train loss: {train_loss} acc: {train_acc}')\n",
    "torch.save(model.state_dict(),PATH)\n",
    "\n",
    "# architecture \n",
    "# loading pickle file and predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f450b323f34dac912b182124b53d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4: Train loss: -0.06355773932907892 acc: 0.11666666666666667\n"
     ]
    }
   ],
   "source": [
    "test_dl= DataLoader(dtest, batch_size=1)\n",
    "num_batches = len(test_dl)\n",
    "y_true_test1 = list()\n",
    "y_pred_test1 = list()\n",
    "total_loss_train = 0\n",
    "tt = tqdm_notebook(iter(test_dl), leave=False, total=num_batch)\n",
    "for we, w in zip(tt,tst_weights):\n",
    "    X = we[0]\n",
    "    y = we[1]\n",
    "    lengths = we[2]\n",
    "    \n",
    "    w = w.reshape(-1,1)\n",
    "    w = w.transpose()\n",
    "\n",
    "    w = Variable(torch.Tensor(w).cpu())\n",
    "    X = Variable(X.cpu())\n",
    "    y = Variable(y.cpu())\n",
    "    lengths = lengths.numpy()\n",
    "\n",
    "    X = X.float()\n",
    "    w = w.float()\n",
    "    y = y.long()\n",
    "    pred = model(X,w)\n",
    "    loss = F.nll_loss(pred, y)\n",
    "\n",
    "\n",
    "    y_true_train += list(y.cpu().data.numpy())\n",
    "    y_pred_train += list(pred_idx.cpu().data.numpy())\n",
    "    total_loss_train += loss.item()\n",
    "\n",
    "train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "train_loss = total_loss_train/len(train_dl)\n",
    "print(f' Epoch {epoch}: Train loss: {train_loss} acc: {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
